<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Slide 1: Title Slide -->
				<section>
					<h1 class="r-frame">LLM Fundamentals</h1>
					<h5>For Developers</h5>
					<aside class="notes">
						<ul>
							<li>My son is now 6 months and we started to give him solids. 
							<li>But the thing is, unless you play this particular Hindi song, he won't start eating. 
							<li>He is certainly not smart yet to relate them consciously. 
							<li>But this song is acting as a cue for him to eat. We have heard the song so many times, we absolutely hate it now. 

							<li>Languages are same, the previous words are cue for the next word </li>
							<li>And that is how LLMs work. </li>
							<li>Not smart, just better at doing the math to predict the next word. </li>
							<li>It literally generates one word at a time. </li>
							<li>The one by one word typed on your screen is not a feature, it is a limitation actually. </li>
							<li>We are not talking about code in this session, we are talking about language in general which of course include code but only as words and symbols.
						</ul> 
						Intro
					</aside>
				</section>
		
				<section>
					<h1>Vibe Check</h1>
					<ul>
						<li>Prompts</li>
						<li>Contexts</li>
					</ul>
					<aside class="notes">
						ok, I am not sure how much you are gonna learn from this, but I am gonna try to explain it in a way that makes sense to me.
					</aside>
				</section>
		
				<!-- Slide 2: Opening Story -->
				<section >
					<img src="images/1.jpeg" alt="The genie story" width="70%" height="70%">
				</section>
				<section >
					<img src="images/2.jpeg" alt="The genie story" width="70%" height="70%">
				</section>
				<section >
					<img src="images/3.jpeg" alt="The genie story" width="70%" height="70%">
				</section>
				<section >
					<img src="images/4.jpeg" alt="The genie story" width="70%" height="70%">
				</section>
				<section >
					<img src="images/5.jpeg" alt="The genie story" width="70%" height="70%">
				</section>
				<section >
					<img src="images/6.jpeg" alt="The genie story" width="70%" height="70%">
					<aside class="notes">
						<ul></ul>
							<li>Imagine you found a magic lamp, and when you rub it, out pops a genie.</li>
							<li>This genie is here to grant your wishes!</li>
							<li>But there’s a catch—this genie has a serious hearing problem.</li>
		
							<li>So, you ask the genie, ‘I wish for a billion dollars!’ The genie scratches his head, says, ‘Got it!’ and poof!—a billion donuts appear.</li>
							<li>You try again: ‘No, no, I meant a billion dollars.’ The genie nods, waves his hand, and this time—poof!—you’re standing inside a room filled with dog collars. Turns out the genie’s pretty bad with details.</li>
							<li>Finally, you get frustrated and say, ‘I just want to be rich!’ The genie grins, waves his hand, and now… poof!… you’re a guy named Rich. Close enough, right?</li>
							<li>This genie, as powerful as it is, really struggles with vague requests. It’ll grant you something, but not quite what you wanted. 
							<li> That’s what working with AI is like. The AI is your genie—it’s incredibly powerful, but if your instructions (prompts) are too vague or lack details, it’ll give you something completely off the mark.</li>
							<li>So, just like with a tricky genie, with AI, you need to be super clear and specific, or you might end up with donuts instead of dollars.</li>
					</aside>
				</section>
		
				<section data-auto-animate>
					<div data-id="box" style="height: 10px; background: salmon;"></div>
				</section>
				<section data-auto-animate>
					<div data-id="box" style="height:70px;  background: rgb(61, 52, 50);">
						<h4 class="r-fit-text r-frame">______ + ______ + ____  = *desired output.</h4>
					</div>
					<aside class="notes">
						So we all want desired output by being specific when we talk to AI.
					</aside>
				</section>
		
			<section>
				<h1 class="r-frame">Prompts</h1>
				<h4>An LLM prompt is an input guiding AI’s generated response.</h4>
				<aside class="notes">
					<ul></ul>
						<li>How do we talk to AI? Thats your prompt.</li>
						<li>One thing we should agree on is:</li>
						<li>LLMs don’t “understand” what you are saying or have “knowledge” they just comes back with the best possible words prediction possible for the set of words you shared. It’s all about probability.</li>
				</aside>
			</section>

			<section data-auto-animate>
				<h3 class="">Prompt</h3>
				<blockquote>
					"Write a program in JavaScript to sort an array.” <br> - is it a good prompt?
				</blockquote>
				<aside class="notes">
					<ul>
						<li>Audience Poll</li>
						<li>What will be the data type of the array?</li>
						<li>It’s too vague. There is no information about the type of array (numbers, strings, mixed types).</li>
						<li>It doesn’t specify the desired sorting order (ascending, descending).</li>
						<li>No mention of edge cases like an empty array, duplicate values, or performance considerations.</li>
					</ul>
				</aside>
			</section>
		
			<section>
				<h3>Good Prompt</h3>
				"Write a JavaScript function that sorts an array of numbers in descending order. The function should handle edge cases such as:
					<ul>
						<li>An empty array.</li>
						<li>Arrays with duplicate numbers.</li>
						<li>Arrays containing both positive and negative integers.</li>
					</ul>
			</section>
		
			<section>
				<h3>Good Prompt Tips</h3>
				<ul>
					<li>Be specific. Don’t shy away from writing long prompts.</li>
					<li>Its more like talking to a 5 year old.</li>
					<li>XML syntax: <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#why-use-xml-tags">Claude AI XML Prompt documentation</a></li>
				</ul>
			</section>

			<section>
				<img src="images/prompt_in_vscode.png" alt="prompt context" >
			</section>
			<section>
				<div data-id="box" style="height:70px;  background: rgb(61, 52, 50);">
					<h4 class="r-fit-text r-frame"> Detailed Prompt + ______ + ____  = *desired output.</h4>
				</div>
			</section>

			<section>
				<h1 class="r-frame">Context</h1>
				<h4>Context tells the LLM what your prompt is about.</h4>
				<aside class="notes">
					<ul>
						<li>Context can be a single sentence, code, image an excel sheet etc.</li>
					</ul>
				</aside>
			</section>

			<section>
				<img src="images/context_is_important.png" alt="context" width="70%" height="70%">
			</section>

			<section>
				<img src="images/sameandruby_context.png" alt="context">	
			</section>

			<section>
				<img src="images/conext_llm_apart.png" alt="context">
			</section>

			<section>
				<img src="images/context_llm_close.png" alt="context" width="80%" height="70%">
				<aside class="notes">
					<ul>
						<li>Word Probability sets as per the context.</li>
						<li>Too much context and model will set more probability to the words that might not be relevant.</li>
						<li>Too much context can cause hallucinations.</li>
						<li>Just add relevant context.</li>
					</ul>
				</aside>
			</section>

			<section>
				<img src="images/context_prompt_zoom_in.png" alt="context" >
			</section>

			<section>
				<h1 class="r-frame">Context Window</h1>
				<h4>The number of tokens (words) the LLM can accept as context.</h4>
				<aside class="notes">
					<ul>
						<li>Context can be a single sentence, code, image an excel sheet etc.</li>
					</ul>
				</aside>
			</section>

			<section>
				<iframe src="https://sdk.vercel.ai/playground" width="100%" height="700px" frameborder="0" scrolling="no"></iframe>
			</section>
			
			<section>
				<img src="images/context_window.png" alt="context window" >
				<aside class="notes">
					<ul>
						<li>The number of tokens is dynamic based on the model you are using.</li>
						<li>The context gets trimmed as you add more context and it exceeds the context window.</li>
					</ul>
				</aside>
			</section>

			<section>
				<h3>Tips</h3>
				<ul>
					<li>Only add relevant context. No too much but not too less either.</li>
					<li>Create a new chat for different context.</li>
					<li>Don't chat for too long in a single session/window as context window will be exceeded.</li>
				</ul>
			</section>

			<section>
				<h3>How to supply context to LLM?</h3>
				<ul>
					<li>Coding Assistants use open files as context.</li>
					<li>Other tools uses codebase indexing and embeddings to supply context.</li>
				</ul>
			</section>

			<section>
				<div data-id="box" style="height:70px;  background: rgb(61, 52, 50);">
					<h4 class="r-fit-text r-frame"> Detailed Prompt + Decent context + ____  = *desired output.</h4>
				</div>
			</section>


			<section>
				<h1 class="r-frame">The Model</h1>
				<h4>But what is a good model?</h4>
				<ul>
					<li>Generally larger models are better. But it depends on their training data.</li>
					<li>The model that are tailored for your needs.</li>
					<li>Like Github copilot, Gemini code assist is for coding, Stable Diffusion is for images. etc</li>
					<li>Using specific models for specific tasks is better.</li>
					<li>Large model is not equals to large context window. Setting a large context window is an model architecture decision.</li>
				</ul>
			</section>

			<section>
				<img src="images/context_llm_close.png" alt="context" width="80%" height="70%">
				<aside class="notes">
					<ul>
						<li>Less neurons, less processing power.</li>
					</ul>
				</aside>
			</section>

			<section>
				<div data-id="box" style="height:70px;  background: rgb(61, 52, 50);">
					<h4 class="r-fit-text r-frame"> Detailed Prompt + Decent context + Good Model  = *desired output.</h4>
				</div>
			</section>

			<section>
				<h1 class="r-frame">Context is King</h1>
			</section>

			<section>
				<h3 class="r-frame"> ChatGPT vs Coding Assistants</h3>
				<ul>
					<li>Trained for coding.</li>
					<li>Multi model support for various purposes. </li>
					<li>IDE integrations, integrated chat, autocompletion via APIs.</li>
					<li>Auto Context awareness</li>
				</ul>
			</section>

			<section>
				<h3 class="r-frame"> Codebase Indexing and Embeddings</h3>
				<ul>
					<li>Trained for coding.</li>
					<li>Multi model support for various purposes. </li>
					<li>IDE integrations, integrated chat, autocompletion via APIs.</li>
					<li>Auto Context awareness</li>
				</ul>
			</section>

			<section>
				<img src="images/coding_assitants.png" alt="codebase indexing" >
			</section>

			<section>
				<h1>
					Takeaways
				</h1>
				<ul>
					<li>Put your mind into the prompt.</li>
					<li>Be mindful of the context.</li>
					<li>For Models: Bigger is better.</li>
					<li>Using coding assistance is the future. It will get better.</li>
				</ul>
			</section>
		
				<!-- Slide 11: Closing + Q&A -->
				<section>
					<h1>Thank you!</h1>
				</section>
		
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
